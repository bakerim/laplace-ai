import pandas as pd
import numpy as np
import joblib
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
from ta.momentum import RSIIndicator
import warnings
import os

# --- YENÄ° EKLENTÄ°: Drive ModÃ¼lÃ¼nÃ¼ Ã‡aÄŸÄ±r ---
from laplace_drive_loader import load_data_from_drive

# Ayarlar
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.simplefilter(action='ignore', category=FutureWarning)

# TICKER artÄ±k dosya ismine baÄŸlÄ± olacak, ama kaydederken yine genel isim kullanÄ±yoruz
LOOKBACK = 60
EPOCHS = 15  # BÃ¼yÃ¼k veri iÃ§in epoch sayÄ±sÄ±nÄ± biraz daha artÄ±rdÄ±m!
BATCH_SIZE = 32
MODEL_NAME = "laplace_lstm_model.h5"
FEATURE_SCALER_NAME = "laplace_feature_scaler.pkl"
PRICE_SCALER_NAME = "laplace_price_scaler.pkl"

def add_technical_indicators(df):
    """Veriye RSI ve Hacim kontrollerini ekler"""
    # Veri setinde 'Close' ve 'Volume' olduÄŸundan emin olalÄ±m
    if 'Close' not in df.columns or 'Volume' not in df.columns:
        print("âš ï¸ HATA: CSV dosyasÄ±nda 'Close' veya 'Volume' sÃ¼tunu bulunamadÄ±.")
        return None

    rsi_indicator = RSIIndicator(close=df["Close"], window=14)
    df["RSI"] = rsi_indicator.rsi()
    df["Volume"] = df["Volume"].replace(0, np.nan)
    df.dropna(inplace=True)
    return df

def create_and_train_model():
    print(f"ğŸ“¡ Veri KaynaÄŸÄ±: GOOGLE DRIVE")
    
    # 1. Veriyi Drive'dan Ã‡ek
    df = load_data_from_drive()
    
    if df is None:
        print("âŒ EÄŸitim iptal edildi. Veri yok.")
        return

    # 2. Ä°ndikatÃ¶rleri Ekle
    print("ğŸ§ª Teknik indikatÃ¶rler hesaplanÄ±yor...")
    df = add_technical_indicators(df)
    if df is None: return
    
    # KullanacaÄŸÄ±mÄ±z Ã–zellikler
    dataset = df[['Close', 'Volume', 'RSI']].values
    
    print("âš–ï¸ Veriler Ã¶lÃ§eklendiriliyor...")
    feature_scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = feature_scaler.fit_transform(dataset)
    
    price_scaler = MinMaxScaler(feature_range=(0, 1))
    price_scaler.fit(df[['Close']].values)
    
    # EÄŸitim Verisi HazÄ±rlama
    x_train, y_train = [], []
    for i in range(LOOKBACK, len(scaled_data)):
        x_train.append(scaled_data[i-LOOKBACK:i])
        y_train.append(scaled_data[i, 0])
        
    x_train, y_train = np.array(x_train), np.array(y_train)
    
    print(f"ğŸ§  Model inÅŸa ediliyor (Veri Boyutu: {x_train.shape[0]} satÄ±r)...")
    
    model = Sequential()
    model.add(Input(shape=(x_train.shape[1], x_train.shape[2])))
    model.add(LSTM(units=100, return_sequences=True)) # Birim sayÄ±sÄ±nÄ± 50'den 100'e Ã§Ä±kardÄ±k (Daha bÃ¼yÃ¼k beyin)
    model.add(Dropout(0.2))
    model.add(LSTM(units=100, return_sequences=False))
    model.add(Dropout(0.2))
    model.add(Dense(units=50))
    model.add(Dense(units=1))
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    
    print(f"ğŸ”¥ EÄŸitim baÅŸladÄ± ({EPOCHS} Epoch)...")
    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)
    
    print("ğŸ’¾ Dosyalar kaydediliyor...")
    model.save(MODEL_NAME)
    joblib.dump(feature_scaler, FEATURE_SCALER_NAME)
    joblib.dump(price_scaler, PRICE_SCALER_NAME)
    
    print(f"âœ… BAÅARILI! Model Drive verisiyle eÄŸitildi.")

if __name__ == "__main__":
    create_and_train_model()
